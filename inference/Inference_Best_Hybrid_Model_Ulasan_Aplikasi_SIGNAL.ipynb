{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Inference Model Hybrid Terbaik**"
      ],
      "metadata": {
        "id": "6HfAOqbrlwef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji coba model hybrid terbaik untuk ulasan pengguna aplikasi SIGNAL yang belum terlihat sama sekali oleh model hybrid."
      ],
      "metadata": {
        "id": "hKX1o9DXlzso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COftu_zOmMUX",
        "outputId": "248b2a51-7ada-44d0-86bd-0829b2d335b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Class Indonesian Roberta Feature Extractor (Arsitektur Model Hybrid)**"
      ],
      "metadata": {
        "id": "lJPL6Qzdl8ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indonesian Roberta di sini digunakan sebagai model yang bertugas untuk mengekstraksi fitur dari bentuk huruf ke dalam bentuk numerik atau representasi vektor. Repositori model nya dapat diakses di sini:\n",
        "\n",
        "https://huggingface.co/w11wo/indonesian-roberta-base-sentiment-classifier"
      ],
      "metadata": {
        "id": "M-me7FjtmBE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library pemodelan\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "VV_BYjWJmdq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konfigurasi variabel global\n",
        "# Runtime CUDA\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "BTOLdT2QmqgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class untuk arsitektur model hybrid\n",
        "class HybridRoberta(nn.Module):\n",
        "    def __init__(self, model_name, n_classes, head_type, hidden_dim):\n",
        "        super(HybridRoberta, self).__init__()\n",
        "\n",
        "        self.head_type = head_type.lower()\n",
        "        print(f\"Menginisialisasi Model Hybrid: RoBERTa + {self.head_type.upper()}...\")\n",
        "\n",
        "        # Base Model (Feature Extractor)\n",
        "        self.roberta = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Freeze sebagian layer RoBERTa agar training lebih cepat & hemat memori (Opsional dan Kondisional)\n",
        "        # Hapus komentarnya jika GPU Out of Memory\n",
        "        # for param in self.roberta.parameters():\n",
        "        #     param.requires_grad = False\n",
        "\n",
        "        # Ukuran output RoBERTa base = 768\n",
        "        self.roberta_dim = 768\n",
        "\n",
        "        # Define Head (LSTM / GRU / CNN)\n",
        "        if self.head_type == 'lstm':\n",
        "            self.head = nn.LSTM(\n",
        "                input_size=self.roberta_dim,\n",
        "                hidden_size=hidden_dim,\n",
        "                num_layers=1,\n",
        "                batch_first=True,\n",
        "                bidirectional=True\n",
        "            )\n",
        "            self.classifier = nn.Linear(hidden_dim * 2, n_classes) # *2 karena Bidirectional\n",
        "\n",
        "        elif self.head_type == 'gru':\n",
        "            self.head = nn.GRU(\n",
        "                input_size=self.roberta_dim,\n",
        "                hidden_size=hidden_dim,\n",
        "                num_layers=1,\n",
        "                batch_first=True,\n",
        "                bidirectional=True\n",
        "            )\n",
        "            self.classifier = nn.Linear(hidden_dim * 2, n_classes)\n",
        "\n",
        "        elif self.head_type == 'cnn':\n",
        "            # CNN 1D untuk teks\n",
        "            self.head = nn.Conv1d(\n",
        "                in_channels=self.roberta_dim,\n",
        "                out_channels=hidden_dim,\n",
        "                kernel_size=3, # Filter size (melihat 3 kata sekaligus)\n",
        "                padding=1\n",
        "            )\n",
        "            self.classifier = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Tipe head harus 'lstm', 'gru', atau 'cnn'\")\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Feature Extraction dengan RoBERTa\n",
        "        # output: (batch_size, seq_len, 768)\n",
        "        roberta_out = self.roberta(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "\n",
        "        # Masuk ke Head (Hybrid)\n",
        "        if self.head_type in ['lstm', 'gru']:\n",
        "            # LSTM/GRU Output: (batch, seq_len, hidden*2)\n",
        "            output, _ = self.head(roberta_out)\n",
        "            # Mean Pooling: Ambil rata-rata semua token output\n",
        "            output = torch.mean(output, dim=1)\n",
        "\n",
        "        elif self.head_type == 'cnn':\n",
        "            # CNN butuh input (batch, channels, seq_len), lakukan permute\n",
        "            # roberta_out: (batch, 768, seq_len)\n",
        "            roberta_out = roberta_out.permute(0, 2, 1)\n",
        "\n",
        "            output = self.head(roberta_out)\n",
        "            # output: (batch, hidden_dim, seq_len)\n",
        "\n",
        "            # Global Max Pooling (Ambil fitur paling menonjol)\n",
        "            output = F.max_pool1d(output, kernel_size=output.shape[2])\n",
        "            # output: (batch, hidden_dim, 1) -> Squeeze jadi (batch, hidden_dim)\n",
        "            output = output.squeeze(2)\n",
        "\n",
        "        # Klasifikasi\n",
        "        output = self.dropout(output)\n",
        "        return self.classifier(output)"
      ],
      "metadata": {
        "id": "LohqxMVjl-6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk load model hybrid terbaik untuk inference\n",
        "def load_model_inference(model_path, head_type):\n",
        "    print(f\"Loading model: {head_type.upper()}...\")\n",
        "    MODEL_NAME = \"w11wo/indonesian-roberta-base-sentiment-classifier\"\n",
        "\n",
        "    # Arsitektur Hybrid Model\n",
        "    model = HybridRoberta(\n",
        "        model_name=MODEL_NAME,\n",
        "        n_classes=3,\n",
        "        head_type=head_type,\n",
        "        hidden_dim=256\n",
        "    )\n",
        "\n",
        "    # Isi dengan Bobot (.bin)\n",
        "    # map_location=device (agar jalan di CPU)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval() # Set mode evaluasi\n",
        "\n",
        "    # Load Tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "9TQpaEKTmxi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Uji Coba Model Hybrid Terbaik dengan Data Baru**"
      ],
      "metadata": {
        "id": "50MjBQbitpLH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wZCswOwjecT"
      },
      "outputs": [],
      "source": [
        "# Fungsi klasifikasi sentimen ulasan aplikasi SIGNAL\n",
        "def predict_sentiment(text, model, tokenizer):\n",
        "    encoded_review = tokenizer.encode_plus(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        add_special_tokens=True,\n",
        "        return_token_type_ids=False,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_review['input_ids'].to(device)\n",
        "    attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad(): # Hemat memori\n",
        "        output = model(input_ids, attention_mask)\n",
        "        _, prediction = torch.max(output, dim=1)\n",
        "\n",
        "    class_names = ['Negatif', 'Netral', 'Positif']\n",
        "    return class_names[prediction]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "# Upload file .bin model hybrid terbaik (Roberta+GRU)\n",
        "model_gru, tokenizer = load_model_inference('best_model_skema2_gru.bin', head_type='gru')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfMguJji-CtL",
        "outputId": "dd1f8759-3215-4e5d-e692-6e111881752c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: GRU...\n",
            "Menginisialisasi Model Hybrid: RoBERTa + GRU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at w11wo/indonesian-roberta-base-sentiment-classifier and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uji model hybrid terbaik dengan ulasan bebas\n",
        "# Tes Prediksi untuk ulasan positif\n",
        "review_pos = input(\"Masukkan ulasan aplikasi SIGNAL (Positif): \")\n",
        "hasil_pos = predict_sentiment(review_pos, model_gru, tokenizer)\n",
        "\n",
        "print(f\"Review: {review_pos}\")\n",
        "print(f\"Sentimen: {hasil_pos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyWEVpfkqMYf",
        "outputId": "df362536-4100-43df-99fc-4e9e71658845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukkan ulasan aplikasi SIGNAL (Positif): aplikasi nya ngebantu banget jadi saya ga perlu datang ke kantor, simpel tinggal lewat HP\n",
            "Review: aplikasi nya ngebantu banget jadi saya ga perlu datang ke kantor, simpel tinggal lewat HP\n",
            "Sentimen: Positif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tes Prediksi untuk ulasan negatif\n",
        "review_neg = input(\"Masukkan ulasan aplikasi SIGNAL (Negatif): \")\n",
        "hasil_neg = predict_sentiment(review_neg, model_gru, tokenizer)\n",
        "\n",
        "print(f\"Review: {review_neg}\")\n",
        "print(f\"Sentimen: {hasil_neg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7u47Q6Q-QAO",
        "outputId": "64e6f10b-a7bf-4568-ee91-986602ec44e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukkan ulasan aplikasi SIGNAL (Negatif): aplikasi lambat buang-buang waktu aja \n",
            "Review: aplikasi lambat buang-buang waktu aja \n",
            "Sentimen: Negatif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tes Prediksi untuk ulasan netral\n",
        "review_net = input(\"Masukkan ulasan aplikasi SIGNAL (Netral): \")\n",
        "hasil_net = predict_sentiment(review_net, model_gru, tokenizer)\n",
        "\n",
        "print(f\"Review: {review_net}\")\n",
        "print(f\"Sentimen: {hasil_net}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYJIJu2b-TMZ",
        "outputId": "6904621c-09a1-4357-8e7e-64c6d99057c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukkan ulasan aplikasi SIGNAL (Netral): bayar pajak online bisa lewat aplikasi SIGNAL\n",
            "Review: bayar pajak online bisa lewat aplikasi SIGNAL\n",
            "Sentimen: Netral\n"
          ]
        }
      ]
    }
  ]
}